{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merged_lstm():\n",
    "    embedding_layer = Embedding(nb_words,\n",
    "            embedding_dim,\n",
    "            weights=[word_embedding_matrix],\n",
    "            input_length=seq_length,\n",
    "            trainable=False)\n",
    "    \n",
    "    lstm_layer = LSTM(128, dropout=0.25, recurrent_dropout=0.2,\n",
    "                     go_backwards = False, implementation = 2)\n",
    "\n",
    "    sequence_1_input = Input(shape=(seq_length,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(seq_length,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    dense_input = Input(shape = (ncols,))\n",
    "    d = Dense(256, kernel_initializer = 'he_normal')(dense_input)\n",
    "    d = PReLU()(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Dropout(0.4)(d)\n",
    "    \n",
    "    d2 = Dense(512, kernel_initializer = 'he_normal')(d)\n",
    "    d2 = PReLU()(d2)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "    \n",
    "    d3 = Dense(512, kernel_initializer = 'he_normal')(d2)\n",
    "    d3 = PReLU()(d3)\n",
    "    d3 = BatchNormalization()(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "    \n",
    "    merged = concatenate([x1, y1, d3])\n",
    "    merged = Dropout(0.25)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(256)(merged)\n",
    "    merged = PReLU()(merged)\n",
    "    merged = Dropout(0.25)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    preds = Dense(1, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[sequence_1_input, sequence_2_input, dense_input], outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "embedding_dim = 300\n",
    "nb_words = 120594\n",
    "\n",
    "data_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/transformed/keras_tokenizer/'\n",
    "word_embedding_matrix = np.load(data_src + 'embedding_matrix.npy')\n",
    "\n",
    "q_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "\n",
    "q1 = np.load(q_src + 'q1train_NER_128len.npy')\n",
    "q2 = np.load(q_src + 'q2train_NER_128len.npy')\n",
    "X_train = pd.read_pickle('Xtrain_814colsBest.pkl', compression = 'bz2')\n",
    "X_train = X_train.astype('float32')\n",
    "y = pd.read_csv(feats_src + '/the_1owl/owl_train.csv')['is_duplicate'].values\n",
    "\n",
    "test = False\n",
    "if test:\n",
    "    q1_te = np.load(q_src + 'q1test_NER_128len.npy')\n",
    "    q2_te = np.load(q_src + 'q2test_NER_128len.npy')\n",
    "    X_test = pd.read_pickle('Xtest_814colsBest.pkl', compression = 'bz2')\n",
    "    X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_foldrun(X, q1, q2, y, X_test = None, q1_test = None, q2_test = None, start_fold = 0):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 10, random_state = 111, shuffle = True)\n",
    "    if isinstance(X, pd.core.frame.DataFrame):\n",
    "        X = X.values\n",
    "    if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "        X_test = X_test.values\n",
    "    if isinstance(y, pd.core.frame.DataFrame):\n",
    "        y = y.is_duplicate.values\n",
    "    if isinstance(y, pd.core.frame.Series):\n",
    "        y = y.values\n",
    "    \n",
    "    i = 0\n",
    "    losses = []\n",
    "    train_splits = []\n",
    "    val_splits = []\n",
    "    for tr_index, val_index in skf.split(X, y):\n",
    "        train_splits.append(tr_index)\n",
    "        val_splits.append(val_index)\n",
    "        \n",
    "    oof_train = np.zeros((404290))\n",
    "    oof_test = np.zeros((10, 2345796))\n",
    "    \n",
    "    for i in range(start_fold, 10):\n",
    "        X_tr, X_val = X[train_splits[i]], X[val_splits[i]]\n",
    "        q1_tr, q1_val = q1[train_splits[i]], q1[val_splits[i]]\n",
    "        q2_tr, q2_val = q2[train_splits[i]], q2[val_splits[i]]\n",
    "        y_tr, y_val = y[train_splits[i]], y[val_splits[i]]\n",
    "\n",
    "        t = time.time()\n",
    "        print('Start training on fold: {}'.format(i))\n",
    "        callbacks = [ModelCheckpoint('checks/mergedlstm_10SKF_fold{}.h5'.format(i),\n",
    "                                    monitor='val_loss', \n",
    "                                    verbose = 0, save_best_only = True),\n",
    "                 EarlyStopping(monitor='val_loss', patience = 4, verbose = 1)]\n",
    "        \n",
    "        model = merged_lstm()\n",
    "        model.fit([q1_tr, q2_tr, X_tr], y_tr, validation_data=([q1_val, q2_val, X_val], y_val),\n",
    "                epochs=200, batch_size=512, callbacks = callbacks)\n",
    "        \n",
    "        val_pred = model.predict([q1_val, q2_val, X_val], batch_size = 64)\n",
    "        oof_train[val_splits[i]] = val_pred\n",
    "        score = log_loss(y_val, val_pred)\n",
    "        losses.append(score)\n",
    "        print('Predicting training set.')\n",
    "        if X_test is not None:\n",
    "            print('Predicting test set.')\n",
    "            test_preds = model.predict([q1_te, q2_te, X_test], batch_size = 64)\n",
    "            oof_test[i, :] = test_preds\n",
    "        print('Final score for fold {} :'.format(i), score, '\\n',\n",
    "              'Time it took to train and predict on fold:', time.time() - t, '\\n')\n",
    "        del X_tr, X_val, q1_tr, q1_val, q2_tr, q2_val\n",
    "        gc.collect()\n",
    "        i += 1\n",
    "        \n",
    "    oof_train = pd.DataFrame(oof_train)\n",
    "    oof_train.columns = ['merged_lstm_prob']\n",
    "    oof_train.to_pickle('OOF_preds/train_MergedLSTMpreds_fold{}.pkl'.format(i))\n",
    "    if X_test is not None:\n",
    "        oof_test = pd.DataFrame(oof_test)\n",
    "        oof_test.columns = ['merged_lstm_prob']\n",
    "        oof_test.to_pickle('OOF_preds/test_MergedLSTMpreds_fold{}.pkl'.format(i))\n",
    "    print('Mean logloss for model in 10-folds SKF:', np.array(losses).mean(axis = 0))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ncols = X_train.shape[1]\n",
    "lstm_foldrun(X_train, q1, q2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
