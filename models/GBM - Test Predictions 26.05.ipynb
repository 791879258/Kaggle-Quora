{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import difflib\n",
    "import time\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.spatial.distance import cosine, correlation, canberra, chebyshev, minkowski, jaccard, euclidean\n",
    "\n",
    "from models_utils_gbm import *\n",
    "from models_utils_fe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "    feats_src2 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "    \n",
    "    keras_q1 = np.load(feats_src2 + 'q1test_NER_128len.npy')\n",
    "    keras_q2 = np.load(feats_src2 + 'q2test_NER_128len.npy')\n",
    "    xgb_feats = pd.read_csv(feats_src + '/the_1owl/owl_test.csv')\n",
    "    abhishek_feats = pd.read_csv(feats_src + 'abhishek/test_features.csv',\n",
    "                              encoding = 'ISO-8859-1').iloc[:, 2:]\n",
    "    text_feats = pd.read_csv(feats_src + 'other_features/text_features_test.csv',\n",
    "                            encoding = 'ISO-8859-1')\n",
    "    img_feats = pd.read_csv(feats_src + 'other_features/img_features_test.csv')\n",
    "    srk_feats = pd.read_csv(feats_src + 'srk/SRK_grams_features_test.csv')\n",
    "    \n",
    "    mephisto_feats = pd.read_csv('../../data/features/lemmatized_fullclean/test_mephistopeheles_features.csv').iloc[:, 6:]\n",
    "    turkewitz_feats = pd.read_csv('../../data/features/lemmatized_fullclean/test_turkewitz_features_fullcleanSTEMMED.csv')\n",
    "    turkewitz_feats = turkewitz_feats[['q1_freq', 'q2_freq']]\n",
    "    turkewitz_feats['freq_sum'] = turkewitz_feats.q1_freq + turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_diff'] = turkewitz_feats.q1_freq - turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_mult'] = turkewitz_feats.q1_freq * turkewitz_feats.q2_freq\n",
    "    turkewitz_feats['freq_div'] = turkewitz_feats.q1_freq / turkewitz_feats.q2_freq\n",
    "\n",
    "    xgb_feats.drop(['z_len1', 'z_len2', 'z_word_len1', 'z_word_len2'], axis = 1, inplace = True)\n",
    "    xgb_feats = xgb_feats.iloc[:, 5:]\n",
    "    \n",
    "    df = pd.concat([xgb_feats, abhishek_feats, text_feats, img_feats, \n",
    "                               turkewitz_feats, mephisto_feats], axis = 1)\n",
    "    del xgb_feats, abhishek_feats, text_feats, img_feats, turkewitz_feats, mephisto_feats\n",
    "    gc.collect()\n",
    "    \n",
    "    df = drop_duplicate_cols(df)\n",
    "    keras_q1 = pd.DataFrame(keras_q1)\n",
    "    keras_q2 = pd.DataFrame(keras_q2)\n",
    "    keras_q1.columns = ['question1_{}'.format(i) for i in range(keras_q1.shape[1])]\n",
    "    keras_q2.columns = ['question2_{}'.format(i) for i in range(keras_q2.shape[1])]\n",
    "    X = pd.concat([keras_q1, keras_q2, df], axis = 1)\n",
    "    \n",
    "    colnames_list = X.columns.tolist()\n",
    "    colnames_list[300] = 'len_char_q1_other'\n",
    "    colnames_list[301] = 'len_char_q2_other'\n",
    "    X.columns = colnames_list\n",
    "    print('Test data shape:', X.shape)\n",
    "    X = X.astype('float32')\n",
    "    return X\n",
    "\n",
    "def predict_test_xgb(X_test, model_name):\n",
    "    print('Predicting on test set with XGBoost.')\n",
    "    gbm = xgb.Booster(model_file = 'saved_models/XGB/{}.txt'.format(model_name))\n",
    "    X_test = xgb.DMatrix(X_test)\n",
    "    test_preds = gbm.predict(X_test)\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = test_preds\n",
    "    sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "    sample_sub.to_csv(sub_src + '{}.csv'.format(model_name), index = False)\n",
    "    return\n",
    "\n",
    "def predict_test_lgbm(X_test, model_name):\n",
    "    print('Predicting on test set with LightGBM.')\n",
    "    gbm = lgb.Booster(model_file = 'saved_models/LGBM/{}.txt'.format(model_name))\n",
    "    test_preds = gbm.predict(X_test)\n",
    "    sub_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/submissions/'\n",
    "    sample_sub = pd.read_csv(sub_src + 'sample_submission.csv')\n",
    "    sample_sub['is_duplicate'] = test_preds\n",
    "    sample_sub.is_duplicate = sample_sub.is_duplicate.apply(transform)\n",
    "    sample_sub.to_csv(sub_src + '{}.csv'.format(model_name), index = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "trans_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/transformations/'\n",
    "\n",
    "wmd = pd.read_csv(src + 'test_WMD_cleaned_stemmed.csv')\n",
    "wmd = wmd.astype('float32')\n",
    "wmd.replace(np.inf, 1000, inplace = True)\n",
    "\n",
    "skip_thought = pd.read_csv(src + 'test_skipthoughts_Alex_distances.csv')\n",
    "skip_thought = skip_thought.astype('float32')\n",
    "\n",
    "compression = pd.read_csv(src + 'test_LZMAcompression_distance.csv')\n",
    "compression = compression.astype('float32')\n",
    "\n",
    "edit = pd.read_csv(src + 'test_EDITdistance.csv')\n",
    "edit = edit.astype('float32')\n",
    "\n",
    "moments = pd.read_csv(src + 'test_doc2vec_moments.csv')\n",
    "moments = moments.astype('float32')\n",
    "\n",
    "networks_NER = pd.read_csv(src + 'test_networkfeats_NER.csv')\n",
    "networks_NER = networks_NER.astype('float32')\n",
    "\n",
    "lsaq1 = pd.DataFrame(np.load(trans_src + 'test_lsa50_CV1gram.npy')[0])\n",
    "lsaq1.columns = ['{}_lsaCV1_q1'.format(i) for i in range(lsaq1.shape[1])]\n",
    "lsaq2 = pd.DataFrame(np.load(trans_src + 'test_lsa50_CV1gram.npy')[1])\n",
    "lsaq2.columns = ['{}_lsaCV1_q2'.format(i) for i in range(lsaq2.shape[1])]\n",
    "lsaq1 = lsaq1.astype('float32')\n",
    "lsaq2 = lsaq2.astype('float32')\n",
    "\n",
    "svdq1 = pd.DataFrame(np.load(trans_src + 'test_svd50_CV1gram.npy')[0])\n",
    "svdq1.columns = ['{}_svdCV1_q1'.format(i) for i in range(svdq1.shape[1])]\n",
    "svdq2 = pd.DataFrame(np.load(trans_src + 'test_svd50_CV1gram.npy')[1])\n",
    "svdq2.columns = ['{}_svdCV1_q2'.format(i) for i in range(svdq2.shape[1])]\n",
    "svdq1 = svdq1.astype('float32')\n",
    "svdq2 = svdq2.astype('float32')\n",
    "\n",
    "#nmfq1 = pd.DataFrame(pd.read_pickle(src + 'te_nmf.pkl'))\n",
    "#nmfq1.columns = ['{}_nmf'.format(i) for i in range(nmfq1.shape[1])]\n",
    "#nmfq1 = nmfq1.astype('float32')\n",
    "\n",
    "X_test = pd.read_pickle('Xtest_500bestCols.pkl')\n",
    "X_test = pd.concat([X_test, wmd, skip_thought, compression, edit, moments, networks_NER, \n",
    "                     lsaq1, lsaq2, svdq1, svdq2], axis = 1)\n",
    "\n",
    "del wmd, skip_thought, compression, edit, moments, networks_NER, \\\n",
    "    lsaq1, lsaq2, svdq1, svdq2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_cols = [\n",
    "    'min_pagerank_sp_network_weighted',\n",
    "    'norm_wmd',\n",
    "    'word_match',\n",
    "    '1wl_tfidf_l2_euclidean',\n",
    "    'm_vstack_svd_q1_q1_euclidean',\n",
    "    '1wl_tfidf_cosine',\n",
    "    'sk_bi_skew_q2vec',\n",
    "    'm_q1_q2_tf_svd0',\n",
    "    'sk_bi_skew_q1vec',\n",
    "    'skew_q2vec',\n",
    "    'trigram_tfidf_cosine',\n",
    "    'sk_uni_skew_q2vec',\n",
    "    'sk_bi_canberra_distance',\n",
    "    'question1_3',\n",
    "    'sk_uni_skew_q1vec',\n",
    "    'sk_uni_kur_q2vec',\n",
    "    'min_eigenvector_centrality_np_network_weighted',\n",
    "    'avg_world_len2',\n",
    "    'z_word_match',\n",
    "    'sk_uni_kur_q1vec',\n",
    "    'skew_doc2vec_pretested_lemmat']\n",
    "\n",
    "rescale = False\n",
    "X_bin = bin_numerical(X_test, best_cols, 0.1)\n",
    "X_grouped = group_featbyfeat(X_test, best_cols, 'mean')\n",
    "X_grouped2 = group_featbyfeat(X_test, best_cols, 'sum')\n",
    "X_combinations = feature_combinations(X_test, best_cols[:5])\n",
    "\n",
    "X_additional = pd.concat([X_bin, X_grouped, X_grouped2, X_combinations], axis = 1)\n",
    "#X_additional = drop_duplicate_cols(X_additional)\n",
    "X_additional.replace(np.inf, 999, inplace = True)\n",
    "X_additional.replace(np.nan, -999, inplace = True)\n",
    "if rescale:\n",
    "    colnames = X_additional.columns\n",
    "    X_additional = pd.DataFrame(MinMaxScaler().fit_transform(X_additional))\n",
    "    X_additional.columns = colnames\n",
    "\n",
    "X_test = pd.concat([X_test, X_additional], axis = 1)\n",
    "X_test = X_test.astype('float32')\n",
    "print('Final test data shape:', X_test.shape)\n",
    "\n",
    "del X_bin, X_grouped, X_grouped2, X_combinations, X_additional\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/scripts/features/'\n",
    "feats_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/uncleaned/'\n",
    "trans_src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized_fullclean/transformations/'\n",
    "\n",
    "X_test = pd.read_pickle('Xtest_814colsBest.pkl', compression = 'bz2')\n",
    "test_interactions = pd.read_pickle(src + 'test_tony_interaction_gru.pkl')\n",
    "\n",
    "X_test = pd.concat([X_test, test_interactions], axis = 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "del test_interactions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_cols = pd.read_pickle('Cols_currentBest_400feats.pkl')\n",
    "X_test2 = X_test.loc[:, best_cols]\n",
    "X_test2.to_pickle('Xtest_currentBest_400feats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set with XGBoost.\n"
     ]
    }
   ],
   "source": [
    "predict_test_xgb(X_test, 'XGB_10SKF_FredFeatsGRUandDecompAttention_loss0.17354_fold1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set with LightGBM.\n"
     ]
    }
   ],
   "source": [
    "predict_test_lgbm(X_test, 'LGBM_10SKF_FredFeatsGRUandDecompAttention_loss0.17440_fold1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
