{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cPickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "np.random.seed(669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr = pd.read_csv('Unused/train_june2015_full.csv')\n",
    "y_tr = pd.read_csv('train_june2015_labels.csv').values.ravel()\n",
    "\n",
    "X_val = pd.read_csv('Unused/val_may2016_full.csv')\n",
    "y_val = pd.read_csv('val_may2016_labels.csv').values.ravel()\n",
    "y_val_prevs = pd.read_csv('val_may2016_previousproducts.csv').values\n",
    "y_val_mapk = cPickle.load(open('val_may2016_mapklabelspickle.p', 'rb'))\n",
    "\n",
    "X_tr.columns = clean + owned4 + owned3 + owned2 + owned1 + owned0\n",
    "X_val.columns = clean + owned4 + owned3 + owned2 + owned1 + owned0\n",
    "\n",
    "add_tr = pd.read_csv('FULL_train_june2015_5lags.csv').loc[:, ['age', 'antiguedad', 'renta']]\n",
    "add_val = pd.read_csv('FULL_val_may2016_5lags.csv').loc[:, ['age', 'antiguedad', 'renta']]\n",
    "\n",
    "add_tr.columns = ['age2', 'antiguedad2', 'renta2']\n",
    "add_val.columns = ['age2', 'antiguedad2', 'renta2']\n",
    "\n",
    "add_tr2 = pd.read_csv('FULL_train_june2015_5lags.csv').loc[:, ['fecha_alta']]\n",
    "add_val2 = pd.read_csv('FULL_val_may2016_5lags.csv').loc[:, ['fecha_alta']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = [x for x in X_tr.columns if 'ult1' not in x]\n",
    "cats.remove('indrel_1mes')\n",
    "prods = [x for x in X_tr.columns if 'ult1' in x]\n",
    "change = [x for x in X_tr.columns if 'change' in x]\n",
    "\n",
    "orig_prods = prods[0:24]\n",
    "prods = prods[24:]\n",
    "\n",
    "lag1 = [x for x in X_tr.columns if '_4' in x]\n",
    "lag2 = [x for x in X_tr.columns if '_3' in x]\n",
    "lag3 = [x for x in X_tr.columns if '_2' in x]\n",
    "lag4 = [x for x in X_tr.columns if '_1' in x][2:]\n",
    "lag5 = [x for x in X_tr.columns if '_0' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr.drop(orig_prods, 1, inplace = True)\n",
    "X_val.drop(orig_prods, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lags2 = lag1 + lag2 + lag3 + lag4 + lag5\n",
    "lags = [lag1, lag2, lag3, lag4, lag5]\n",
    "\n",
    "def get_diffs(X1):\n",
    "    \n",
    "    X_tr = X1.copy()\n",
    "\n",
    "    diff2 = pd.DataFrame(X_tr[lag1].values - X_tr[lag2].values)\n",
    "    sum2 = pd.DataFrame(X_tr[lag1].values + X_tr[lag2].values)\n",
    "    prod2 = pd.DataFrame(X_tr[lag1].values * X_tr[lag2].values)\n",
    "\n",
    "    diff3 = pd.DataFrame(X_tr[lag2].values - X_tr[lag3].values)\n",
    "    sum3 = pd.DataFrame(X_tr[lag2].values + X_tr[lag3].values)\n",
    "    prod3 = pd.DataFrame(X_tr[lag2].values * X_tr[lag3].values)\n",
    "\n",
    "    diff4 = pd.DataFrame(X_tr[lag3].values - X_tr[lag4].values)\n",
    "    sum4 = pd.DataFrame(X_tr[lag3].values + X_tr[lag4].values)\n",
    "    prod4 = pd.DataFrame(X_tr[lag3].values * X_tr[lag4].values)\n",
    "    \n",
    "    diff1 = pd.DataFrame(X_tr[lag4].values - X_tr[lag5].values)\n",
    "    sum1 = pd.DataFrame(X_tr[lag4].values + X_tr[lag5].values)\n",
    "    prod1 = pd.DataFrame(X_tr[lag4].values * X_tr[lag5].values)\n",
    "    \n",
    "    X_tr = pd.concat([X_tr, sum2, sum3, sum4, sum1, \n",
    "                      diff2, diff3, diff4, diff1,\n",
    "                      prod2, prod3, prod4, prod1], 1)\n",
    "    \n",
    "    return X_tr\n",
    "\n",
    "\n",
    "def add(X1):\n",
    "    \n",
    "    X = X1.copy()\n",
    "    \n",
    "    X['sum_cats'] = X[cats].sum(axis = 1)\n",
    "    X['mean_cats'] = X[cats].mean(axis = 1)\n",
    "    X['std_cats'] = X[cats].std(axis = 1)\n",
    "    X['max_cats'] = np.amax(X[cats], axis = 1)\n",
    "    \n",
    "    X['sum_prods'] = X[prods].sum(axis = 1)\n",
    "    X['mean_prods'] = X[prods].mean(axis = 1)\n",
    "    X['std_prods'] = X[prods].std(axis = 1)\n",
    "    X['max_prods'] = np.amax(X[prods], axis = 1)\n",
    "    \n",
    "    X['sum_change'] = X[change].sum(axis = 1)\n",
    "    X['mean_change'] = X[change].mean(axis = 1)\n",
    "    X['std_change'] = X[change].std(axis = 1)\n",
    "    X['max_change'] = np.amax(X[change], axis = 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def prods_sums(X1):\n",
    "    \n",
    "    prods_names = []\n",
    "    for i in change:\n",
    "        j = i.replace('_ult1_change', '')\n",
    "        prods_names.append(j)\n",
    "    \n",
    "    prods_groups = []\n",
    "    for i, j in zip(prods, prods_names):\n",
    "        prod = [x for x in prods if j in x]\n",
    "        prods_groups.append(prod)\n",
    "\n",
    "    X = X1.copy()\n",
    "    sums = []\n",
    "    for i, j in zip(prods_groups, prods_names):\n",
    "        \n",
    "        prod_sum = np.sum(X[i], axis = 1)\n",
    "        X['{} sum'.format(j)] = prod_sum\n",
    "        sums.append(prod_sum)\n",
    "        \n",
    "    \"\"\"    \n",
    "    sums = np.sum(sums, axis = 1).astype('int64')\n",
    "    X_proportions = X.iloc[:, -24:].divide(sums, axis = 1)\n",
    "    X = pd.concat([X, X_proportions], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def age_clean(df):\n",
    "    df.loc[df.age2 < 18,\"age2\"]  = df.loc[(df.age2 >= 18) & (df.age2 <= 30),\"age2\"].mean(skipna=True)\n",
    "    df.loc[df.age2 > 100,\"age2\"] = df.loc[(df.age2 >= 30) & (df.age2 <= 100),\"age2\"].mean(skipna=True)\n",
    "    df[\"age2\"].fillna(df[\"age2\"].mean(),inplace=True)\n",
    "    df[\"age2\"] = df[\"age2\"].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Try to cut every 30 days and every 365\n",
    "\n",
    "def cut_alta(df):\n",
    "    alta_range = np.arange(0, np.max(df.fecha_alta), 30)\n",
    "    df.fecha_alta = pd.cut(df.fecha_alta, alta_range, right=True)\n",
    "    df.fecha_alta = pd.factorize(df.fecha_alta, sort = True)[0]\n",
    "    return df\n",
    "\n",
    "def cut_renta(df):\n",
    "    renta_ranges = [0]+range(20000, 200001, 10000)\n",
    "    renta_ranges += range(300000, 1000001, 100000)+[2000000, 100000000]\n",
    "    df['renta'] = pd.cut(df.renta2, renta_ranges, right=True)\n",
    "    df.renta = pd.factorize(df.renta, sort = True)[0]\n",
    "    return df\n",
    "# Try with sort and without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr2 = pd.concat([X_tr, add_tr, add_tr2], 1)\n",
    "X_val2 = pd.concat([X_val, add_val, add_val2], 1)\n",
    "\n",
    "X_tr2 = cut_renta(X_tr2)\n",
    "X_val2 = cut_renta(X_val2)\n",
    "\n",
    "X_tr2['renta2'] = np.log(X_tr2['renta2'])\n",
    "X_val2['renta2'] = np.log(X_val2['renta2'])\n",
    "\n",
    "X_tr2.drop(['indrel_1mes'], 1, inplace = True)\n",
    "X_val2.drop(['indrel_1mes'], 1, inplace = True)\n",
    "\n",
    "X_tr2 = age_clean(X_tr2)\n",
    "X_val2 = age_clean(X_val2)\n",
    "\n",
    "X_tr2 = cut_alta(X_tr2)\n",
    "X_val2 = cut_alta(X_val2)\n",
    "\n",
    "\n",
    "cats2 = [x for x in X_tr2.columns if 'ult1' not in x]\n",
    "ohs = ['pais_residencia', 'segmento', 'canal_entrada', 'ind_empleado', 'nomprov']\n",
    "\n",
    "\n",
    "X_tr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('Unused/test_full.csv')\n",
    "test_prevs = pd.read_csv('test_previousproducts.csv').values\n",
    "\n",
    "X_test.columns = clean + owned4 + owned3 + owned2 + owned1 + owned0\n",
    "\n",
    "add_te = pd.read_csv('FULL_test_5lags.csv').loc[:, ['age', 'antiguedad', 'renta']]\n",
    "add_te2 = pd.read_csv('FULL_test_5lags.csv').loc[:, ['fecha_alta']]\n",
    "\n",
    "add_te.columns = ['age2', 'antiguedad2', 'renta2']\n",
    "\n",
    "\n",
    "X_test.drop(orig_prods, 1, inplace = True)\n",
    "\n",
    "X_test = pd.concat([X_test, add_te, add_te2], 1)\n",
    "X_test = cut_renta(X_test)\n",
    "X_test['renta2'] = np.log(X_test['renta2'])\n",
    "X_test.drop(['indrel_1mes'], 1, inplace = True)\n",
    "X_test = age_clean(X_test)\n",
    "X_test = cut_alta(X_test)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "cats2 = cats[:-2]\n",
    "\n",
    "def prep_poly(X_tr, X_val, test = False, X_test = None):\n",
    "\n",
    "    X_tr2 = add(X_tr)\n",
    "    X_val2 = add(X_val)\n",
    "    if test:\n",
    "        X_test = add(X_test)\n",
    "\n",
    "    poly = PolynomialFeatures(2)\n",
    "    poly.fit(X_tr2[cats2])\n",
    "    tr = pd.DataFrame(poly.transform(X_tr2[cats2]))\n",
    "    val = pd.DataFrame(poly.transform(X_val2[cats2]))\n",
    "    if test:\n",
    "        te = pd.DataFrame(poly.transform(X_test[cats2]))\n",
    "    \n",
    "    X_tr2 = get_diffs(X_tr2)\n",
    "    X_val2 = get_diffs(X_val2)\n",
    "    print X_tr2.shape\n",
    "    if test:\n",
    "        X_test = get_diffs(X_test)\n",
    "\n",
    "    X_tr3 = pd.concat([X_tr2, tr], 1)\n",
    "    X_val3 = pd.concat([X_val2, val], 1)\n",
    "    print X_tr3.shape\n",
    "    if test:\n",
    "        X_test = pd.concat([X_test, te], 1)\n",
    "        \n",
    "    if test:\n",
    "        return X_tr3, X_val3, X_test\n",
    "    \n",
    "    return X_tr3, X_val3\n",
    "\n",
    "\n",
    "\n",
    "#X_tr3, X_val3 = prep_poly(X_tr2, X_val2)\n",
    "\n",
    "X_tr2, X_val2, X_test = prep_poly(X_tr2, X_val2, True, X_test)\n",
    "\n",
    "print X_tr2.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "comb4 = 'indext,indresi,ind_nuevo,segmento,indrel,ind_actividad_cliente,ind_empleado,' \\\n",
    "        'tiprel_1mes,antiguedad,fecha_alta,age,sexo,renta'.split(',')\n",
    "    \n",
    "comb1 = 'indext,indresi,ind_nuevo,segmento,indrel,ind_actividad_cliente,ind_empleado,' \\\n",
    "        'tiprel_1mes,antiguedad,fecha_alta'.split(',')\n",
    "\n",
    "comb2 = 'segmento,age,ind_empleado,indfall,renta'.split(',')\n",
    "\n",
    "comb3 = 'nomprov,canal_entrada,pais_residencia'.split(',')\n",
    "\n",
    "\n",
    "def combs(X, one = False, ones_three = False, ones_four = False, two = False, two_three = False,\n",
    "          three = False, three_three = False):\n",
    "    \n",
    "    X_tr = X.copy()\n",
    "    \n",
    "    if one:\n",
    "        for comb in itertools.combinations(comb1, 2):\n",
    "            feat = comb[0] + \"_\" + comb[1]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]]\n",
    "        print 'Comb1 interactions done.'\n",
    "        \n",
    "    if ones_three:\n",
    "        for comb in itertools.combinations(comb1, 3):\n",
    "            feat = comb[0] + \"_\" + comb[1] + \"_\" + comb[2]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]] + X_tr[comb[2]]\n",
    "        print '3-way Comb1 interactions done.'\n",
    "    \n",
    "    if ones_four:\n",
    "    \n",
    "        for comb in itertools.combinations(comb1, 4):\n",
    "            feat = comb[0] + \"_\" + comb[1] + \"_\" + comb[2] + \"_\" + comb[3]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]] + X_tr[comb[2]] + X_tr[comb[3]]\n",
    "        print '4-way Comb1 interactions done.'\n",
    "    \n",
    "    if two:\n",
    "        for comb in itertools.combinations(comb2, 2):\n",
    "            feat = comb[0] + \"_\" + comb[1]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]]\n",
    "        print 'Comb2 interactions done.'\n",
    "        \n",
    "    if two_three:\n",
    "        for comb in itertools.combinations(comb2, 3):\n",
    "            feat = comb[0] + \"_\" + comb[1] + \"_\" + comb[2]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]] + X_tr[comb[2]]\n",
    "        print '3-way Comb2 interactions done.'\n",
    "        \n",
    "    if three:\n",
    "        for comb in itertools.combinations(comb3, 2):\n",
    "            feat = comb[0] + \"_\" + comb[1]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]]\n",
    "        print 'Comb3 interactions done.'\n",
    "        \n",
    "    if three_three:\n",
    "        for comb in itertools.combinations(comb3, 3):\n",
    "            feat = comb[0] + \"_\" + comb[1] + \"_\" + comb[2]\n",
    "            X_tr[feat] = X_tr[comb[0]] + X_tr[comb[1]] + X_tr[comb[2]]\n",
    "        print '3-way Comb3 interactions done.'\n",
    "        \n",
    "    print X_tr.shape\n",
    "    return X_tr\n",
    "\n",
    "X_tr2 = combs(X_tr2, True, True, False, True)\n",
    "X_val2 = combs(X_val2, True, True, False, True)\n",
    "X_test = combs(X_test, True, True, False, True)\n",
    "\n",
    "\n",
    "X_tr2 = prods_sums(X_tr2)\n",
    "X_val2 = prods_sums(X_val2)\n",
    "X_test = prods_sums(X_test)\n",
    "\n",
    "print X_tr2.shape\n",
    "print X_val2.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def new(X_train, X_val, name, var1, var2):\n",
    "    \n",
    "    X_tr4 = X_train.copy()\n",
    "    X_val4 = X_val.copy()\n",
    "    \n",
    "    X_tr4['{}'.format(name)] = (X_tr4.groupby(var1))[var2].transform('mean')\n",
    "    X_val4['{}'.format(name)] = (X_val4.groupby(var1))[var2].transform('mean')\n",
    "    \n",
    "    return X_tr4, X_val4\n",
    "\n",
    "def new_test(X_te, name, var1, var2):\n",
    "    \n",
    "    X_test = X_te.copy()\n",
    "    X_test['{}'.format(name)] = (X_test.groupby(var1))[var2].transform('mean')\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "\n",
    "def add_cols(X_train, X_val, X_te = None):\n",
    "    \n",
    "    X_tr4 = X_train.copy()\n",
    "    X_val4 = X_val.copy()\n",
    "    if X_te is not None:\n",
    "         X_test = X_te.copy()\n",
    "\n",
    "    # by hand:\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'tiprel_by_actividad', 'ind_actividad_cliente', 'tiprel_1mes')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_change_by_renta', 'renta', 'sum_change')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_change_by_actividad', 'ind_actividad_cliente', 'sum_change')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_change_by_age', 'age', 'sum_change')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_change_by_sexo', 'sexo', 'sum_change')\n",
    "\n",
    "    # from adder2:\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_prods_groupingby_lags', lags2, 'sum_prods')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'indext_groupingby_lags', lags2, 'indext')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'ind_empleado_groupingby_lags', lags2 ,'ind_empleado')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'nomprov_groupingby_lags', lags2, 'nomprov')\n",
    "\n",
    "\n",
    "    # from adder3:\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'sum_prods_groupingby_change', change, 'sum_prods')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'indext_groupingby_change', change, 'indext')\n",
    "    \n",
    "    #from adder_3way:\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'ind_actividad_cliente+segmento_groupingby_sum_change_mean2',\n",
    "                        ['ind_actividad_cliente', 'segmento'], 'sum_change')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'ind_actividad_cliente+segmento_groupingby_sum_prods_mean2',\n",
    "                        ['ind_actividad_cliente', 'segmento'], 'sum_prods')\n",
    "    X_tr4, X_val4 = new(X_tr4, X_val4, 'ind_actividad_cliente+tiprel_1mes_groupingby_fecha_alta_mean2',\n",
    "                        ['ind_actividad_cliente', 'tiprel_1mes'], 'fecha_alta')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if X_te is not None:\n",
    "         # by hand:\n",
    "        X_test = new_test(X_test, 'tiprel_by_actividad', 'ind_actividad_cliente', 'tiprel_1mes')\n",
    "        X_test = new_test(X_test, 'sum_change_by_renta', 'renta', 'sum_change')\n",
    "        X_test = new_test(X_test, 'sum_change_by_actividad', 'ind_actividad_cliente', 'sum_change')\n",
    "        X_test = new_test(X_test, 'sum_change_by_age', 'age', 'sum_change')\n",
    "        X_test = new_test(X_test, 'sum_change_by_sexo', 'sexo', 'sum_change')\n",
    "\n",
    "        # from adder2:\n",
    "        X_test = new_test(X_test, 'sum_prods_groupingby_lags', lags2, 'sum_prods')\n",
    "        X_test = new_test(X_test, 'indext_groupingby_lags', lags2, 'indext')\n",
    "        X_test = new_test(X_test, 'ind_empleado_groupingby_lags', lags2 ,'ind_empleado')\n",
    "        X_test = new_test(X_test, 'nomprov_groupingby_lags', lags2, 'nomprov')\n",
    "\n",
    "\n",
    "        # from adder3:\n",
    "        X_test = new_test(X_test, 'sum_prods_groupingby_change', change, 'sum_prods')\n",
    "        X_test = new_test(X_test, 'indext_groupingby_change', change, 'indext')\n",
    "        \n",
    "        #from adder_3way:\n",
    "        X_test = new_test(X_test, 'ind_actividad_cliente+segmento_groupingby_sum_change_mean2',\n",
    "                        ['ind_actividad_cliente', 'segmento'], 'sum_change')\n",
    "        X_test = new_test(X_test, 'ind_actividad_cliente+segmento_groupingby_sum_prods_mean2',\n",
    "                        ['ind_actividad_cliente', 'segmento'], 'sum_prods')\n",
    "        X_test = new_test(X_test, 'ind_actividad_cliente+tiprel_1mes_groupingby_fecha_alta_mean2',\n",
    "                        ['ind_actividad_cliente', 'tiprel_1mes'], 'fecha_alta')\n",
    "\n",
    "    print X_tr4.shape\n",
    "    print X_val4.shape\n",
    "    \n",
    "    if X_te is not None:\n",
    "        print X_tr4.shape\n",
    "        print X_val4.shape\n",
    "        print X_test.shape\n",
    "        \n",
    "        return X_tr4, X_val4, X_test\n",
    "    \n",
    "    return X_tr4, X_val4\n",
    "\n",
    "\n",
    "#X_tr4, X_val4 = add_cols(X_tr4, X_val4)\n",
    "\n",
    "X_tr2, X_val2, X_test = add_cols(X_tr2, X_val2, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "prods_names = []\n",
    "for i in change:\n",
    "    j = i.replace('_ult1_change', '')\n",
    "    prods_names.append(j)\n",
    "\n",
    "prods_groups = []\n",
    "for i, j in zip(prods, prods_names):\n",
    "    prod = [x for x in prods if j in x]\n",
    "    prods_groups.append(prod)\n",
    "    \n",
    "\n",
    "def new(X, name, var1, var2, func):\n",
    "    \n",
    "    X1 = X.copy()\n",
    "    X1['{}'.format(name)] = (X1.groupby(var1))[var2].transform('{}'.format(func))\n",
    "    \n",
    "    return X1\n",
    "\n",
    "def add_groups(X, var, func, concat = False, X2 = None):\n",
    "    \n",
    "    X1 = X.copy()\n",
    "\n",
    "    X1 = new(X1, '{}_gr1'.format(var), prods_groups[0], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr2'.format(var), prods_groups[1], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr3'.format(var), prods_groups[2], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr4'.format(var), prods_groups[3], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr5'.format(var), prods_groups[4], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr6'.format(var), prods_groups[5], '{}'.format(var), '{}'.format(func))\n",
    "\n",
    "    X1 = new(X1, '{}_gr7'.format(var), prods_groups[6], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr8'.format(var), prods_groups[7], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr9'.format(var), prods_groups[8], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr10'.format(var), prods_groups[9], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr11'.format(var), prods_groups[10], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr12'.format(var), prods_groups[11],  '{}'.format(var), '{}'.format(func))\n",
    "\n",
    "    X1 = new(X1, '{}_gr13'.format(var), prods_groups[12], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr14'.format(var), prods_groups[13], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr15'.format(var), prods_groups[14], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr16'.format(var), prods_groups[15], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr17'.format(var), prods_groups[16], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr18'.format(var), prods_groups[17], '{}'.format(var), '{}'.format(func))\n",
    "\n",
    "    X1 = new(X1, '{}_gr19'.format(var), prods_groups[18], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr20'.format(var), prods_groups[19], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr21'.format(var), prods_groups[20], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr22'.format(var), prods_groups[21], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr23'.format(var), prods_groups[22], '{}'.format(var), '{}'.format(func))\n",
    "    X1 = new(X1, '{}_gr24'.format(var), prods_groups[23], '{}'.format(var), '{}'.format(func))\n",
    "    \n",
    "    cols = X1.iloc[:, -24:]\n",
    "    if concat:\n",
    "        X_f = pd.concat([X2, cols], 1)\n",
    "        \n",
    "        return X_f\n",
    "    \n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr3 = add_groups(X_tr2, 'sum_change', 'mean', True, X_tr2)\n",
    "X_val3 = add_groups(X_val2, 'sum_change', 'mean', True, X_val2)\n",
    "\n",
    "X_tr3 = add_groups(X_tr3, 'sum_prods', 'mean', True, X_tr3)\n",
    "X_val3 = add_groups(X_val3, 'sum_prods', 'mean', True, X_val3)\n",
    "\n",
    "print X_tr3.shape\n",
    "print X_val3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del X_tr2, X_val2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test2 = add_groups(X_test, 'sum_change', 'mean', True, X_test)\n",
    "X_test2 = add_groups(X_test2, 'sum_prods', 'mean', True, X_test2)\n",
    "print X_test2.shape\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_tr3, y_tr)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'multiclass',\n",
    "    'num_class': 24,\n",
    "    'metric' : {'multi_logloss'},\n",
    "    'num_leaves' : 181,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.3762,\n",
    "    'bagging_fraction': 0.9606,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'bagging_freq': 100,\n",
    "    'max_depth': 7,\n",
    "    'silent': 1,\n",
    "    'random_state': 2016,\n",
    "    'verbose': 0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round = int(185/0.9),\n",
    "                verbose_eval = 50)\n",
    "\n",
    "\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "val_pred = gbm.predict(X_val3, num_iteration=gbm.best_iteration)\n",
    "score = predict(val_pred, y_val_prevs, y_val_mapk, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_pred = gbm.predict(X_test2, num_iteration = gbm.best_iteration)\n",
    "test_pred[:, 0] = 0\n",
    "test_pred[:, 1] = 0\n",
    "\n",
    "test_final = predict(test_pred, test_prevs)\n",
    "test_sub = create_sub2(msg, test_final, 'LGBM_GroupedbyProdsGroupsFULL_21.11 MAP: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 111)\n",
    "\n",
    "\n",
    "def lgbm_skf(Xtr, Xval, predict_test = False):\n",
    "    \n",
    "    scores = []\n",
    "    val_preds = []\n",
    "    test_preds= []\n",
    "    \n",
    "    i = 1\n",
    "    t = time.time()\n",
    "    \n",
    "    for train, test in skf.split(Xtr, y_tr):\n",
    "        \n",
    "        X_train, X_valid = Xtr.values[train], Xtr.values[test]\n",
    "        y_train, y_valid = y_tr[train], y_tr[test]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "        # specify your configurations as a dict\n",
    "        params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'multiclass',\n",
    "            'num_class': 24,\n",
    "            'metric' : {'multi_logloss'},\n",
    "            'num_leaves' : 190,\n",
    "            'learning_rate' : 0.05,\n",
    "            'feature_fraction' : 0.4091,\n",
    "            'bagging_fraction': 0.9922,\n",
    "            'min_data_in_leaf': 14,\n",
    "            'bagging_freq': 100,\n",
    "            'max_depth': 7,\n",
    "            'silent': 1,\n",
    "            'random_state': 2016,\n",
    "            'verbose': 0,\n",
    "        }\n",
    "\n",
    "\n",
    "        print 'Training on fold :', i\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round = 10000,\n",
    "                        valid_sets = [lgb_train, lgb_eval], early_stopping_rounds = 15,\n",
    "                        verbose_eval = False)\n",
    "\n",
    "        val_pred = gbm.predict(Xval, num_iteration=gbm.best_iteration)\n",
    "        val_pred[:, 0] = 0\n",
    "        val_pred[:, 1] = 0\n",
    "        \n",
    "        if predict_test:\n",
    "            test_pred = gbm.predict(X_test2, num_iteration = gbm.best_iteration)\n",
    "            \n",
    "        score = predict(val_pred, y_val_prevs, y_val_mapk, True)\n",
    "        scores.append(score)\n",
    "        \n",
    "        val_preds.append(val_pred)\n",
    "        if predict_test:\n",
    "            test_preds.append(test_pred)\n",
    "        i += 1\n",
    "        \n",
    "    val_preds = np.array(val_preds).mean(axis = 0)\n",
    "    if predict_test:\n",
    "        test_preds = np.array(test_preds).mean(axis = 0)\n",
    "    \n",
    "    final_score = predict(val_preds, y_val_prevs, y_val_mapk, True)\n",
    "    \n",
    "    print 'Mean score :', np.array(scores).mean()\n",
    "    print 'Final MAP :', final_score\n",
    "    print 'Time it took:', time.time() - t\n",
    "    \n",
    "    if predict_test:\n",
    "        return val_preds, test_preds, final_score\n",
    "    \n",
    "    return val_preds\n",
    "\n",
    "#val_preds = lgbm_skf(X_tr3, X_val3, False)\n",
    "\n",
    "vals, tests, final_score = lgbm_skf(X_tr3, X_val3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Final MAP : 0.859232472062\n",
    "Mean score: 0.8555\n",
    "Time it took: 471.421617985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tests[:, 0] = 0\n",
    "tests[:, 1] = 0\n",
    "\n",
    "test_final = predict(tests, test_prevs)\n",
    "test_sub = create_sub2(msg, test_final, 'LGBM_GroupedbyProdsGroups_21.11 MAP: {}'.format(final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lgbm_skf_bo(bagging_fraction, feature_fraction, max_depth, min_data_in_leaf, num_leaves):\n",
    "    \n",
    "    scores = []\n",
    "    val_preds = []\n",
    "    test_preds= []\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for train, test in skf.split(X_tr2, y_tr):\n",
    "        \n",
    "        X_train, X_valid = X_tr2.values[train], X_tr2.values[test]\n",
    "        y_train, y_valid = y_tr[train], y_tr[test]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "\n",
    "        params = {\n",
    "                'task' : 'train',\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective' : 'multiclass',\n",
    "                'num_class': 24,\n",
    "                'metric' : {'multi_logloss'},\n",
    "                'num_leaves' : num_leaves,\n",
    "                'learning_rate' : 0.05,\n",
    "                'feature_fraction' : feature_fraction,\n",
    "                'bagging_fraction' :bagging_fraction,\n",
    "                'min_data_in_leaf': min_data_in_leaf,\n",
    "                'bagging_freq': 100,\n",
    "                'max_depth': max_depth,\n",
    "                'silent': 1,\n",
    "                'random_state': 2016,\n",
    "                'verbose': 0,\n",
    "                }\n",
    "\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['min_data_in_leaf'] = int(min_data_in_leaf)\n",
    "        params['max_depth'] = int(max_depth)\n",
    "        params['num_leaves'] = int(num_leaves)\n",
    "\n",
    "\n",
    "        print 'Training on fold :', i\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round = 10000,\n",
    "                        valid_sets = [lgb_train, lgb_eval], early_stopping_rounds = 15,\n",
    "                        verbose_eval = 100)\n",
    "\n",
    "        val_pred = gbm.predict(X_val2, num_iteration=gbm.best_iteration)\n",
    "        val_pred[:, 0] = 0\n",
    "        val_pred[:, 1] = 0\n",
    "        \n",
    "            \n",
    "        score = predict(val_pred, y_val_prevs, y_val_mapk, True)\n",
    "        scores.append(score)\n",
    "        \n",
    "        val_preds.append(val_pred)\n",
    "        i += 1\n",
    "        \n",
    "    val_preds = np.array(val_preds).mean(axis = 0)\n",
    "    \n",
    "    final_score = predict(val_preds, y_val_prevs, y_val_mapk, True)\n",
    "    \n",
    "    print 'Mean score :', np.array(scores).mean()\n",
    "    print 'Final MAP :', final_score\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Final MAP : 0.853861719695\n",
    "   29 | 05m39s |    0.85386 |             0.9922 |             0.4091 |      7.4666 |            14.1727 |     189.6892 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "lgbmBO2 = BayesianOptimization(lgbm_skf_bo, {\n",
    "        'bagging_fraction': (0.9, 1),\n",
    "        'feature_fraction': (0.35, 0.6),\n",
    "        'max_depth': (5, 9),\n",
    "        'min_data_in_leaf': (7, 25),\n",
    "        'num_leaves': (170, 220),\n",
    "    })\n",
    "\n",
    "num_iter = 35\n",
    "init_points = 20\n",
    "\n",
    "lgbmBO2.maximize(init_points=init_points, n_iter=num_iter)\n",
    "\n",
    "print('LGBM: %f' % lgbmBO2.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_tr2, y_tr)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'multiclass',\n",
    "    'num_class': 24,\n",
    "    'metric' : {'multi_logloss'},\n",
    "    'num_leaves' : 181,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.3762,\n",
    "    'bagging_fraction': 0.9606,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'bagging_freq': 100,\n",
    "    'max_depth': 7,\n",
    "    'silent': 1,\n",
    "    'random_state': 2016,\n",
    "    'verbose': 0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round = int(185/0.9),\n",
    "                verbose_eval = 50)\n",
    "\n",
    "\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "val_pred = gbm.predict(X_val2, num_iteration=gbm.best_iteration)\n",
    "score = predict(val_pred, y_val_prevs, y_val_mapk, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_preds = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "test_final = predict(test_preds, test_prevs)\n",
    "test_sub = create_sub2(msg, test_final, 'LGBM_GroupedInteractions_20.11_FULL MAP: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dataset2 import Dataset\n",
    "from average_precision import mapk\n",
    "from genetic_search import genetic_search\n",
    "\n",
    "def predict(preds, prevs, labels = None, validate = False):\n",
    "    \n",
    "    preds = preds\n",
    "    filtered_rank = np.equal(prevs, 0) * preds\n",
    "    predictions = np.argsort(filtered_rank, axis=1)\n",
    "    predictions = predictions[:,::-1][:,0:7]\n",
    "    \n",
    "    if validate:\n",
    "        score = mapk(labels, predictions)\n",
    "        print \"MAP:\", score\n",
    "        return score\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "dataset_root = '/home/w/DS_Projects/Kaggle/scripts/'\n",
    "dataset = Dataset(dataset_root)\n",
    "\n",
    "msg = {'train_month': [5],\n",
    "       'eval_month': [16],\n",
    "      'input_columns': [],\n",
    "      'use_product': True,\n",
    "      'use_change': True,\n",
    "    }\n",
    "\n",
    "def create_sub2(msg, preds, filename, verbose = True, save = True):\n",
    "    \n",
    "    test_month = 17\n",
    "    msg['month'] = test_month\n",
    "    predictions = preds\n",
    "    #Create the submission text\n",
    "    if verbose: print 'Creating text...'\n",
    "    text='ncodpers,added_products\\n'\n",
    "    for i, ncodpers in enumerate(dataset.eval_current[dataset.eval_current.fecha_dato == test_month].ncodpers):\n",
    "        text += '%i,' % ncodpers\n",
    "        for j in predictions[i]:\n",
    "            text += '%s ' % dataset.product_columns[j]\n",
    "        text += '\\n'\n",
    "    #Write to file\n",
    "    if verbose: print 'Writing to file...'\n",
    "    if save:\n",
    "        with gzip.open(dataset_root + 'submissions/%s.csv.gz' % filename, 'w') as f:\n",
    "            f.write(text)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "dictionary_types = {\n",
    "                            \"sexo\":'category',\n",
    "                            \"ult_fec_cli_1t\":str,\n",
    "                            \"indresi\":'category',\n",
    "                            \"indext\":'category',\n",
    "                            \"indrel\":'category',\n",
    "                            \"indfall\":'category',\n",
    "                            \"nomprov\":'category',\n",
    "                            \"segmento\":'category',\n",
    "                            \"ind_empleado\":'category',\n",
    "                            \"pais_residencia\":'category',\n",
    "                            \"indrel\":'category',\n",
    "                            \"antiguedad\":np.int16,\n",
    "                            \"ind_nuevo\":'category',\n",
    "                            'indrel_1mes':'category',\n",
    "                            'tiprel_1mes':'category',\n",
    "                            'canal_entrada':'category',\n",
    "                            \"age\":np.int8,\n",
    "                            \"ind_actividad_cliente\":'category',\n",
    "                            \"ind_ahor_fin_ult1\":np.int8,\n",
    "                            \"ind_aval_fin_ult1\":np.int8,\n",
    "                            \"ind_cco_fin_ult1\":np.int8,\n",
    "                            \"ind_cder_fin_ult1\":np.int8,\n",
    "                            \"ind_cno_fin_ult1\":np.int8,\n",
    "                            \"ind_ctju_fin_ult1\":np.int8,\n",
    "                            \"ind_ctma_fin_ult1\":np.int8,\n",
    "                            \"ind_ctop_fin_ult1\":np.int8,\n",
    "                            \"ind_ctpp_fin_ult1\":np.int8,\n",
    "                            \"ind_deco_fin_ult1\":np.int8,\n",
    "                            \"ind_deme_fin_ult1\":np.int8,\n",
    "                            \"ind_dela_fin_ult1\":np.int8,\n",
    "                            \"ind_ecue_fin_ult1\":np.int8,\n",
    "                            \"ind_fond_fin_ult1\":np.int8,\n",
    "                            \"ind_hip_fin_ult1\":np.int8,\n",
    "                            \"ind_plan_fin_ult1\":np.int8,\n",
    "                            \"ind_pres_fin_ult1\":np.int8,\n",
    "                            \"ind_reca_fin_ult1\":np.int8,\n",
    "                            \"ind_tjcr_fin_ult1\":np.int8,\n",
    "                            \"ind_valo_fin_ult1\":np.int8,\n",
    "                            \"ind_viv_fin_ult1\":np.int8,\n",
    "                            \"ind_nomina_ult1\":np.int8,\n",
    "                            \"ind_nom_pens_ult1\":np.int8,\n",
    "                            \"ind_recibo_ult1\":np.int8,\n",
    "\n",
    "                            \"ind_ahor_fin_ult1_change\":'category',\n",
    "                            \"ind_aval_fin_ult1_change\":'category',\n",
    "                            \"ind_cco_fin_ult1_change\":'category',\n",
    "                            \"ind_cder_fin_ult1_change\":'category',\n",
    "                            \"ind_cno_fin_ult1_change\":'category',\n",
    "                            \"ind_ctju_fin_ult1_change\":'category',\n",
    "                            \"ind_ctma_fin_ult1_change\":'category',\n",
    "                            \"ind_ctop_fin_ult1_change\":'category',\n",
    "                            \"ind_ctpp_fin_ult1_change\":'category',\n",
    "                            \"ind_deco_fin_ult1_change\":'category',\n",
    "                            \"ind_deme_fin_ult1_change\":'category',\n",
    "                            \"ind_dela_fin_ult1_change\":'category',\n",
    "                            \"ind_ecue_fin_ult1_change\":'category',\n",
    "                            \"ind_fond_fin_ult1_change\":'category',\n",
    "                            \"ind_hip_fin_ult1_change\":'category',\n",
    "                            \"ind_plan_fin_ult1_change\":'category',\n",
    "                            \"ind_pres_fin_ult1_change\":'category',\n",
    "                            \"ind_reca_fin_ult1_change\":'category',\n",
    "                            \"ind_tjcr_fin_ult1_change\":'category',\n",
    "                            \"ind_valo_fin_ult1_change\":'category',\n",
    "                            \"ind_viv_fin_ult1_change\":'category',\n",
    "                            \"ind_nomina_ult1_change\":'category',\n",
    "                            \"ind_nom_pens_ult1_change\":'category',\n",
    "                            \"ind_recibo_ult1_change\":'category',\n",
    "                            'product_buy':np.int8, }\n",
    "\n",
    "cols = []\n",
    "\n",
    "for key, val in dictionary_types.iteritems():\n",
    "    if val == 'category':\n",
    "        cols.append(key)\n",
    "        \n",
    "cats = [x for x in cols if 'change' not in x]\n",
    "changes = [x for x in cols if 'change' in x]\n",
    "cats.append('antiguedad')\n",
    "cats.append('age')\n",
    "\n",
    "owned = []\n",
    "\n",
    "for key, val in dictionary_types.iteritems():\n",
    "    if val == np.int8:\n",
    "        owned.append(key)\n",
    "        \n",
    "owned.remove('age')\n",
    "owned.remove('product_buy')\n",
    "\n",
    "full = cats + owned + changes\n",
    "\n",
    "owned4 = []\n",
    "owned3 = []\n",
    "owned2 = []\n",
    "owned1 = []\n",
    "owned0 = []\n",
    "\n",
    "for i in owned:\n",
    "    j = i + \"_4\"\n",
    "    owned4.append(j)\n",
    "\n",
    "for i in owned:\n",
    "    j = i + \"_3\"\n",
    "    owned3.append(j)\n",
    "\n",
    "for i in owned:\n",
    "    j = i + \"_2\"\n",
    "    owned2.append(j)\n",
    "\n",
    "for i in owned:\n",
    "    j = i + \"_1\"\n",
    "    owned1.append(j)\n",
    "\n",
    "for i in owned:\n",
    "    j = i + \"_0\"\n",
    "    owned0.append(j)\n",
    "\n",
    "    \n",
    "clean = full[0:16] + dataset.product_columns + dataset.change_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
