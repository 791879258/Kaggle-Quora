{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import sys\n",
    "import datetime\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import csv\n",
    "import timeit\n",
    "import time\n",
    "import textacy\n",
    "import en_core_web_md\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, ngrams\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models import doc2vec\n",
    "from pylab import plot, show, subplot, specgram, imshow, savefig\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors, NearestCentroid, LSHForest\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, NMF\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "src = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/lemmatized/doc2vec/'\n",
    "q1_vec = np.load(src + 'train_q1_doc2vec_vectors_trainquora.npy')\n",
    "q2_vec = np.load(src + 'train_q2_doc2vec_vectors_trainquora.npy')\n",
    "full_vec = np.concatenate([q1_vec, q2_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats_src2 = '/media/w/1c392724-ecf3-4615-8f3c-79368ec36380/DS Projects/Kaggle/Quora/data/features/NER/'\n",
    "q1_vec = np.load(feats_src2 + 'q1train_NER_128len.npy')\n",
    "q2_vec = np.load(feats_src2 + 'q2train_NER_128len.npy')\n",
    "full_vec = np.concatenate([q1_vec, q2_vec])\n",
    "\n",
    "src_train = 'df_train_spacylemmat_fullclean.csv'\n",
    "src_test = 'df_test_spacylemmat_fullclean.csv'\n",
    "df_train = pd.read_csv(src_train)\n",
    "df_train.fillna('NULL', inplace = True)\n",
    "#df_test = pd.read_csv(src_test)\n",
    "\n",
    "full_questions = df_train.question1.tolist() + df_train.question2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808580/808580 [00:07<00:00, 107473.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took: 395.6474838256836\n"
     ]
    }
   ],
   "source": [
    "f = 128\n",
    "t = AnnoyIndex(f)\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(len(full_vec))):\n",
    "    t.add_item(i, full_vec[i])\n",
    "    \n",
    "t.build(50)\n",
    "t.save('train_doc2vec_annoymodel_50trees_angular.ann')\n",
    "print('Time it took:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 128\n",
    "t = AnnoyIndex(f)\n",
    "t.load('train_doc2vec_annoymodel_50trees_angular.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808580/808580 [00:08<00:00, 100916.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time it took: 181.23257184028625\n"
     ]
    }
   ],
   "source": [
    "f = 128\n",
    "t2 = AnnoyIndex(f, metric = 'euclidean')\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(len(full_vec))):\n",
    "    t2.add_item(i, full_vec[i])\n",
    "    \n",
    "t2.build(50)\n",
    "t2.save('train_doc2vec_annoymodel_50trees_euclidean.ann')\n",
    "print('time it took:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808580/808580 [05:28<00:00, 2464.68it/s]\n",
      "100%|██████████| 808580/808580 [02:16<00:00, 5931.70it/s]\n"
     ]
    }
   ],
   "source": [
    "dists_angular = []\n",
    "for i in tqdm(range(len(full_vec))):\n",
    "    dists_angular.append(t.get_nns_by_item(i, 10, include_distances = True)[1])\n",
    "\n",
    "\n",
    "dists_euclidean = []\n",
    "for i in tqdm(range(len(full_vec))):\n",
    "    dists_euclidean.append(t2.get_nns_by_item(i, 10, include_distances = True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_count_ang02(i):\n",
    "    return len(i[i > 0.2])\n",
    "\n",
    "def get_count_ang04(i):\n",
    "    return len(i[i > 0.4])\n",
    "\n",
    "def get_count_ang05(i):\n",
    "    return len(i[i > 0.5])\n",
    "\n",
    "def get_count_euc100(i):\n",
    "    return len(i[i > 100])\n",
    "\n",
    "def get_count_euc500(i):\n",
    "    return len(i[i > 500])\n",
    "\n",
    "def get_count_euc1000(i):\n",
    "    return len(i[i > 1000])\n",
    "\n",
    "def get_count_euc5000(i):\n",
    "    return len(i[i > 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_angular2 = np.array(dists_angular)\n",
    "dists_euclidean2 = np.array(dists_euclidean)\n",
    "\n",
    "ang_02 = np.apply_along_axis(get_count_ang02, axis = 1, arr = dists_angular2)\n",
    "ang_04 = np.apply_along_axis(get_count_ang04, axis = 1, arr = dists_angular2)\n",
    "ang_05 = np.apply_along_axis(get_count_ang05, axis = 1, arr = dists_angular2)\n",
    "\n",
    "euc_100 = np.apply_along_axis(get_count_euc100, axis = 1, arr = dists_euclidean2)\n",
    "euc_500 = np.apply_along_axis(get_count_euc500, axis = 1, arr = dists_euclidean2)\n",
    "euc_1000 = np.apply_along_axis(get_count_euc1000, axis = 1, arr = dists_euclidean2)\n",
    "euc_5000 = np.apply_along_axis(get_count_euc5000, axis = 1, arr = dists_euclidean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_angular2 = np.array(dists_angular)\n",
    "dists_euclidean2 = np.array(dists_euclidean)\n",
    "\n",
    "x = pd.DataFrame()\n",
    "x['10nn_min_angular_q1'] = np.min(dists_angular2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_mean_angular_q1'] = np.mean(dists_angular2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_max_angular_q1'] = np.max(dists_angular2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_min_angular_q2'] = np.min(dists_angular2[df_train.shape[0]:], axis = 1)\n",
    "x['10nn_mean_angular_q2'] = np.mean(dists_angular2[df_train.shape[0]:], axis = 1)\n",
    "x['10nn_max_angular_q2'] = np.max(dists_angular2[df_train.shape[0]:], axis = 1)\n",
    "\n",
    "x['10nn_min_euclidean_q1'] = np.min(dists_euclidean2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_mean_euclidean_q1'] = np.mean(dists_euclidean2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_max_euclidean_q1'] = np.max(dists_euclidean2[:df_train.shape[0]], axis = 1)\n",
    "x['10nn_min_euclidean_q2'] = np.min(dists_euclidean2[df_train.shape[0]:], axis = 1)\n",
    "x['10nn_mean_euclidean_q2'] = np.mean(dists_euclidean2[df_train.shape[0]:], axis = 1)\n",
    "x['10nn_max_euclidean_q2'] = np.max(dists_euclidean2[df_train.shape[0]:], axis = 1)\n",
    "\n",
    "x['10nn_ang02_neighbors_q1'] = ang_02[:df_train.shape[0]]\n",
    "x['10nn_ang04_neighbors_q1'] = ang_04[:df_train.shape[0]]\n",
    "x['10nn_ang05_neighbors_q1'] = ang_05[:df_train.shape[0]]\n",
    "x['10nn_euc100_neighbors_q1'] = euc_100[:df_train.shape[0]]\n",
    "x['10nn_euc500_neighbors_q1'] = euc_500[:df_train.shape[0]]\n",
    "x['10nn_euc1000_neighbors_q1'] = euc_1000[:df_train.shape[0]]\n",
    "x['10nn_euc5000_neighbors_q1'] = euc_5000[:df_train.shape[0]]\n",
    "\n",
    "x['10nn_ang02_neighbors_q2'] = ang_02[df_train.shape[0]:]\n",
    "x['10nn_ang04_neighbors_q2'] = ang_04[df_train.shape[0]:]\n",
    "x['10nn_ang05_neighbors_q2'] = ang_05[df_train.shape[0]:]\n",
    "x['10nn_euc100_neighbors_q2'] = euc_100[df_train.shape[0]:]\n",
    "x['10nn_euc500_neighbors_q2'] = euc_500[df_train.shape[0]:]\n",
    "x['10nn_euc1000_neighbors_q2'] = euc_1000[df_train.shape[0]:]\n",
    "x['10nn_euc5000_neighbors_q2'] = euc_5000[df_train.shape[0]:]\n",
    "\n",
    "x.to_csv('train_10NN_distances.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
